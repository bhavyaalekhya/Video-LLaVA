# -*- coding: utf-8 -*-
"""videollava_metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VxJYLon7J6eu-YjJnNTEzyaGSSho9MOb
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, precision_score, accuracy_score
import numpy as np

def read_file(error_file):
  with open(error_file, 'r') as file:
    lines = file.readlines()

  gt_line = lines[0].strip()
  predicted_line = lines[1].strip()

  gt_data = gt_line.split('Ground Truth: ')[1].strip('[]').split(',')
  predicted_data = predicted_line.split('Predicted: ')[1].strip('[]').split(',')

  gt_data = [int(x) for x in gt_data]
  predicted_data = [int(x) for x in predicted_data]

  return gt_data, predicted_data

def metrics(ground_truth, predicted):
  modified_gt = np.array(ground_truth)
  modified_pred = np.array(predicted)

  recall = recall_score(modified_gt, modified_pred)

  precision = precision_score(modified_gt, modified_pred)

  f1 = f1_score(modified_gt, modified_pred)

  acc = accuracy_score(modified_gt, modified_pred)

  return recall, precision, f1, acc


def cf_matrix(ground_truth, predicted):
  mat = ConfusionMatrixDisplay(confusion_matrix(ground_truth, predicted))
  mat.plot()

#technique error
tech_gt, tech_pred = read_file('/content/technique_error.txt')

r, p, f1, acc = metrics(tech_gt, tech_pred)
print(f"Technique Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(tech_gt, tech_pred)

#measurement error
me_gt, me_pred = read_file('/content/measurement_error.txt')

r, p, f1, acc = metrics(me_gt, me_pred)
print(f"Measurement Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(me_gt, me_pred)

#missing error
mi_gt, mi_pred = read_file('/content/missing_error.txt')

r, p, f1, acc = metrics(mi_gt, mi_pred)
print(f"Missing Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(mi_gt, mi_pred)

#order error
o_gt, o_pred = read_file('/content/order_error.txt')

r, p, f1, acc = metrics(o_gt, o_pred)
print(f"Order Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(o_gt, o_pred)

#preparataion error
p_gt, p_pred = read_file('/content/preparation_error.txt')

r, p, f1, acc = metrics(p_gt, p_pred)
print(f"Preparation Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(p_gt, p_pred)

#temperature error
temp_gt, temp_pred = read_file('/content/temperature_error.txt')

r, p, f1, acc = metrics(temp_gt, temp_pred)
print(f"Temperature Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(temp_gt, temp_pred)

#combined metrics
gt = np.logical_or.reduce((me_gt, tech_gt, mi_gt, temp_gt, o_gt, p_gt))
pred = np.logical_or.reduce((me_pred, tech_pred, mi_pred, temp_pred, o_pred, p_pred))

r, p, f1, acc = metrics(gt, pred)
print(f"Running Error: Recall: {r} \nPrecision: {p} \nF1: {f1} \nAccuracy: {acc}")

cf_matrix(gt, pred)

#variant 1:
v1_r, v1_p, v1_f1, v1_acc = metrics(gt, mi_pred)
print(f"Variant 1: Recall: {v1_r} \nPrecision: {v1_p} \nF1: {v1_f1} \nAccuracy: {v1_acc}")

cf_matrix(gt, mi_pred)

